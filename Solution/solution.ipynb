{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9991865,"sourceType":"datasetVersion","datasetId":6149504},{"sourceId":269527448,"sourceType":"kernelVersion"}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-29T08:17:54.177115Z","iopub.execute_input":"2025-12-29T08:17:54.177460Z","iopub.status.idle":"2025-12-29T08:17:54.192486Z","shell.execute_reply.started":"2025-12-29T08:17:54.177399Z","shell.execute_reply":"2025-12-29T08:17:54.191879Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/financial-sheets-eda/final_finance_df.csv\n/kaggle/input/financial-sheets-eda/__results__.html\n/kaggle/input/financial-sheets-eda/__notebook__.ipynb\n/kaggle/input/financial-sheets-eda/__output__.json\n/kaggle/input/financial-sheets-eda/custom.css\n/kaggle/input/financial-sheets/Readme.md\n/kaggle/input/financial-sheets/dataset/dataset/Quarter_P_L_2_final.csv\n/kaggle/input/financial-sheets/dataset/dataset/cash_flow_statments_final.csv\n/kaggle/input/financial-sheets/dataset/dataset/t1_prices.csv\n/kaggle/input/financial-sheets/dataset/dataset/Quarter_P_L_1_final.csv\n/kaggle/input/financial-sheets/dataset/dataset/price_final.csv\n/kaggle/input/financial-sheets/dataset/dataset/Balance_Sheet_final.csv\n/kaggle/input/financial-sheets/dataset/dataset/Annual_P_L_2_final.csv\n/kaggle/input/financial-sheets/dataset/dataset/ratios_1_final.csv\n/kaggle/input/financial-sheets/dataset/dataset/ratios_2_final.csv\n/kaggle/input/financial-sheets/dataset/dataset/other_metrics_final.csv\n/kaggle/input/financial-sheets/dataset/dataset/Annual_P_L_1_final.csv\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"%%capture\n# 1. Install Unsloth (Latest)\n!pip install \"unsloth[kaggle-new] @ git+https://github.com/unslothai/unsloth.git\"\n\n# 2. Install dependencies WITHOUT the \"<0.9.0\" restriction on TRL\n# We still use --no-deps on xformers to protect the PyTorch version\n!pip install --no-deps xformers\n!pip install --upgrade --no-cache-dir trl peft accelerate bitsandbytes datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T08:17:54.193828Z","iopub.execute_input":"2025-12-29T08:17:54.194053Z","iopub.status.idle":"2025-12-29T08:18:14.105970Z","shell.execute_reply.started":"2025-12-29T08:17:54.194023Z","shell.execute_reply":"2025-12-29T08:18:14.105158Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"price_path = \"/kaggle/input/financial-sheets/dataset/dataset/price_final.csv\"\nmetrics_path = \"/kaggle/input/financial-sheets/dataset/dataset/other_metrics_final.csv\"\nbalance_path = \"/kaggle/input/financial-sheets/dataset/dataset/Balance_Sheet_final.csv\"\npl_path = \"/kaggle/input/financial-sheets/dataset/dataset/Annual_P_L_1_final.csv\"\n\n# Read CSVs\nprice_df = pd.read_csv(price_path)\nmetrics_df = pd.read_csv(metrics_path)\nbalance_df = pd.read_csv(balance_path)\npl_df = pd.read_csv(pl_path)\n\n# Quick check\nprint(\"Price DataFrame shape:\", price_df.shape)\nprint(\"Metrics DataFrame shape:\", metrics_df.shape)\nprint(\"Balance Sheet shape:\", balance_df.shape)\nprint(\"P&L DataFrame shape:\", pl_df.shape)\n\n# Optionally preview\nprice_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T08:18:14.107332Z","iopub.execute_input":"2025-12-29T08:18:14.107630Z","iopub.status.idle":"2025-12-29T08:18:14.273036Z","shell.execute_reply.started":"2025-12-29T08:18:14.107596Z","shell.execute_reply":"2025-12-29T08:18:14.272393Z"}},"outputs":[{"name":"stdout","text":"Price DataFrame shape: (4668, 34)\nMetrics DataFrame shape: (4668, 44)\nBalance Sheet shape: (4668, 51)\nP&L DataFrame shape: (4668, 58)\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"               Name  BSE Code    NSE Code  \\\n0        20 Microns  533022.0   20MICRONS   \n1  21st Cent. Mgmt.  526921.0  21STCENMGM   \n2           360 ONE  542772.0      360ONE   \n3       3B Blackbio  532067.0      __NA__   \n4   3C IT Solutions  544190.0      __NA__   \n\n                                Industry  Current Price  Return over 3months  \\\n0             Mining / Minerals / Metals         225.20                44.62   \n1                  Finance & Investments          70.44                54.12   \n2                  Finance & Investments         995.85                40.86   \n3                             Healthcare        1184.50                48.07   \n4  Computers - Software - Medium / Small          45.00                  NaN   \n\n   Return over 6months  Volume 1month average  Volume 1week average   Volume  \\\n0                23.16                 729846                816052   312746   \n1               114.43                  34120                 27069    11745   \n2                49.58                1193124               2871837  5329590   \n3                25.94                  21265                  5355     7221   \n4                  NaN                 159500                 81000    74000   \n\n   ...  MACD Signal  MACD Signal Previous Day  Return over 1year  \\\n0  ...         9.09                      8.16             134.11   \n1  ...         3.19                      2.91             185.75   \n2  ...        20.92                     16.98             115.42   \n3  ...        81.34                     82.28             165.64   \n4  ...         0.72                      0.82                NaN   \n\n   Return over 3years  Return over 5years  Volume 1year average  \\\n0               55.29               41.55                203559   \n1               41.50               30.34                 13416   \n2               50.50                 NaN                705325   \n3               22.40               64.50                 13985   \n4                 NaN                 NaN                159500   \n\n   Return over 7years  Return over 10years  Market Capitalization  \\\n0               28.58                20.15                 794.66   \n1               15.32                24.91                  73.96   \n2                 NaN                  NaN               36136.15   \n3               54.44                64.15                1016.66   \n4                 NaN                  NaN                  27.09   \n\n              join_key  \n0   533022.0_20MICRONS  \n1  526921.0_21STCENMGM  \n2      542772.0_360ONE  \n3      532067.0___NA__  \n4      544190.0___NA__  \n\n[5 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>BSE Code</th>\n      <th>NSE Code</th>\n      <th>Industry</th>\n      <th>Current Price</th>\n      <th>Return over 3months</th>\n      <th>Return over 6months</th>\n      <th>Volume 1month average</th>\n      <th>Volume 1week average</th>\n      <th>Volume</th>\n      <th>...</th>\n      <th>MACD Signal</th>\n      <th>MACD Signal Previous Day</th>\n      <th>Return over 1year</th>\n      <th>Return over 3years</th>\n      <th>Return over 5years</th>\n      <th>Volume 1year average</th>\n      <th>Return over 7years</th>\n      <th>Return over 10years</th>\n      <th>Market Capitalization</th>\n      <th>join_key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20 Microns</td>\n      <td>533022.0</td>\n      <td>20MICRONS</td>\n      <td>Mining / Minerals / Metals</td>\n      <td>225.20</td>\n      <td>44.62</td>\n      <td>23.16</td>\n      <td>729846</td>\n      <td>816052</td>\n      <td>312746</td>\n      <td>...</td>\n      <td>9.09</td>\n      <td>8.16</td>\n      <td>134.11</td>\n      <td>55.29</td>\n      <td>41.55</td>\n      <td>203559</td>\n      <td>28.58</td>\n      <td>20.15</td>\n      <td>794.66</td>\n      <td>533022.0_20MICRONS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21st Cent. Mgmt.</td>\n      <td>526921.0</td>\n      <td>21STCENMGM</td>\n      <td>Finance &amp; Investments</td>\n      <td>70.44</td>\n      <td>54.12</td>\n      <td>114.43</td>\n      <td>34120</td>\n      <td>27069</td>\n      <td>11745</td>\n      <td>...</td>\n      <td>3.19</td>\n      <td>2.91</td>\n      <td>185.75</td>\n      <td>41.50</td>\n      <td>30.34</td>\n      <td>13416</td>\n      <td>15.32</td>\n      <td>24.91</td>\n      <td>73.96</td>\n      <td>526921.0_21STCENMGM</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>360 ONE</td>\n      <td>542772.0</td>\n      <td>360ONE</td>\n      <td>Finance &amp; Investments</td>\n      <td>995.85</td>\n      <td>40.86</td>\n      <td>49.58</td>\n      <td>1193124</td>\n      <td>2871837</td>\n      <td>5329590</td>\n      <td>...</td>\n      <td>20.92</td>\n      <td>16.98</td>\n      <td>115.42</td>\n      <td>50.50</td>\n      <td>NaN</td>\n      <td>705325</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>36136.15</td>\n      <td>542772.0_360ONE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3B Blackbio</td>\n      <td>532067.0</td>\n      <td>__NA__</td>\n      <td>Healthcare</td>\n      <td>1184.50</td>\n      <td>48.07</td>\n      <td>25.94</td>\n      <td>21265</td>\n      <td>5355</td>\n      <td>7221</td>\n      <td>...</td>\n      <td>81.34</td>\n      <td>82.28</td>\n      <td>165.64</td>\n      <td>22.40</td>\n      <td>64.50</td>\n      <td>13985</td>\n      <td>54.44</td>\n      <td>64.15</td>\n      <td>1016.66</td>\n      <td>532067.0___NA__</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3C IT Solutions</td>\n      <td>544190.0</td>\n      <td>__NA__</td>\n      <td>Computers - Software - Medium / Small</td>\n      <td>45.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>159500</td>\n      <td>81000</td>\n      <td>74000</td>\n      <td>...</td>\n      <td>0.72</td>\n      <td>0.82</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>159500</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>27.09</td>\n      <td>544190.0___NA__</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 34 columns</p>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"price_cols = price_df.columns.tolist()\nmetrics_cols = metrics_df.columns.tolist()\nbalance_cols = balance_df.columns.tolist()\npl_cols = pl_df.columns.tolist()\n\n\n# Print column names for each\nprint(\"üìà Price DataFrame columns:\")\nprint(price_cols, \"\\n\")\n\nprint(\"üìä Other Metrics DataFrame columns:\")\nprint(metrics_cols, \"\\n\")\n\nprint(\"üìö Balance Sheet DataFrame columns:\")\nprint(balance_cols, \"\\n\")\n\nprint(\"üí∞ Annual P&L DataFrame columns:\")\nprint(pl_cols, \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T08:18:14.273910Z","iopub.execute_input":"2025-12-29T08:18:14.274187Z","iopub.status.idle":"2025-12-29T08:18:14.280083Z","shell.execute_reply.started":"2025-12-29T08:18:14.274162Z","shell.execute_reply":"2025-12-29T08:18:14.279547Z"}},"outputs":[{"name":"stdout","text":"üìà Price DataFrame columns:\n['Name', 'BSE Code', 'NSE Code', 'Industry', 'Current Price', 'Return over 3months', 'Return over 6months', 'Volume 1month average', 'Volume 1week average', 'Volume', 'High price', 'Low price', 'High price all time', 'Low price all time', 'Return over 1day', 'Return over 1week', 'Return over 1month', 'DMA 50', 'DMA 200', 'DMA 50 previous day', 'DMA 200 previous day', 'RSI', 'MACD', 'MACD Previous Day', 'MACD Signal', 'MACD Signal Previous Day', 'Return over 1year', 'Return over 3years', 'Return over 5years', 'Volume 1year average', 'Return over 7years', 'Return over 10years', 'Market Capitalization', 'join_key'] \n\nüìä Other Metrics DataFrame columns:\n['Name', 'BSE Code', 'NSE Code', 'Industry', 'Current Price', 'Price to Sales', 'Price to Free Cash Flow', 'EVEBITDA', 'Current ratio', 'Interest Coverage Ratio', 'PEG Ratio', 'Working Capital to Sales ratio', 'QoQ Profits', 'QoQ Sales', 'Net worth', 'Market Cap to Sales', 'Interest Coverage', 'Enterprise Value to EBIT', 'Debt Capacity', 'Debt To Profit', 'Total Capital Employed', 'CROIC', 'debtplus', 'Leverage', 'Dividend Payout', 'Intrinsic Value', 'cash debt contingent liabilities by mcap', 'Cash by market cap', '52w Index', 'Down from 52w high', 'Up from 52w low', 'From 52w high', 'Mkt Cap To Debt Cap', 'Dividend Payout Ratio', 'Graham', 'Price to Cash Flow', 'ROCE3yr avg', 'PB X PE', 'NCAVPS', 'Market Capt to Cash Flow', 'Altman Z Score', 'Market cap to quarterly profit', 'Market Capitalization', 'join_key'] \n\nüìö Balance Sheet DataFrame columns:\n['Name', 'BSE Code', 'NSE Code', 'Industry', 'Current Price', 'Debt', 'Equity capital', 'Preference capital', 'Reserves', 'Secured loan', 'Unsecured loan', 'Balance sheet total', 'Gross block', 'Revaluation reserve', 'Accumulated depreciation', 'Net block', 'Capital work in progress', 'Investments', 'Current assets', 'Current liabilities', 'Book value of unquoted investments', 'Market value of quoted investments', 'Contingent liabilities', 'Total Assets', 'Working capital', 'Lease liabilities', 'Inventory', 'Trade receivables', 'Face value', 'Cash Equivalents', 'Advance from Customers', 'Trade Payables', 'Number of equity shares preceding year', 'Debt preceding year', 'Working capital preceding year', 'Net block preceding year', 'Gross block preceding year', 'Capital work in progress preceding year', 'Working capital 3Years back', 'Working capital 5Years back', 'Working capital 7Years back', 'Working capital 10Years back', 'Debt 3Years back', 'Debt 5Years back', 'Debt 7Years back', 'Debt 10Years back', 'Net block 3Years back', 'Net block 5Years back', 'Net block 7Years back', 'Market Capitalization', 'join_key'] \n\nüí∞ Annual P&L DataFrame columns:\n['Name', 'BSE Code', 'NSE Code', 'Industry', 'Current Price', 'Sales', 'OPM', 'Profit after tax', 'Return on capital employed', 'EPS', 'Change in promoter holding', 'Sales last year', 'Operating profit last year', 'Other income last year', 'EBIDT last year', 'Depreciation last year', 'EBIT last year', 'Interest last year', 'Profit before tax last year', 'Tax last year', 'Profit after tax last year', 'Extraordinary items last year', 'Net Profit last year', 'Dividend last year', 'Material cost last year', 'Employee cost last year', 'OPM last year', 'NPM last year', 'Operating profit', 'Interest', 'Depreciation', 'EPS last year', 'EBIT', 'Net profit', 'Current Tax', 'Tax', 'Other income', 'Last annual result date', 'Sales preceding year', 'Operating profit preceding year', 'Other income preceding year', 'EBIDT preceding year', 'Depreciation preceding year', 'EBIT preceding year', 'Interest preceding year', 'Profit before tax preceding year', 'Tax preceding year', 'Profit after tax preceding year', 'Extraordinary items preceding year', 'Net Profit preceding year', 'Dividend preceding year', 'OPM preceding year', 'NPM preceding year', 'EPS preceding year', 'Sales preceding 12months', 'Net profit preceding 12months', 'Market Capitalization', 'join_key'] \n\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"## Merging of Data for a Bigger Picture \n\n1.  **Price Data:** Real-time market performance (e.g., Current Price, RSI).\n2.  **Valuation Metrics:** Derived ratios (e.g., P/E, PEG, Debt/Equity).\n3.  **Balance Sheet:** Snapshot of financial position (Assets, Liabilities).\n4.  **Annual P&L:** Historical operating performance (Sales, Expenses, Profits).","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# --- Helper Function for Export ---\ndef export_step(df, filename):\n    \"\"\"Saves a dataframe to CSV and prints a confirmation.\"\"\"\n    df.to_csv(filename, index=False)\n    print(f\"‚úÖ Success: '{filename}' has been generated with {len(df)} rows.\")\n\ndef merge_and_export_master(df_price, df_metrics, df_balance, df_pl, merge_key='BSE Code'):\n    \"\"\"\n    Merges 4 dataframes into one Master Record and exports it.\n    \"\"\"\n    print(\"üîÑ Starting Merge Process...\")\n    \n    # 1. Standardize Keys\n    for df in [df_price, df_metrics, df_balance, df_pl]:\n        df.columns = df.columns.str.strip() \n        if merge_key in df.columns:\n            # Drop duplicates to prevent explosion\n            df.drop_duplicates(subset=[merge_key], inplace=True)\n\n    # 2. Merge Sequence (Outer Joins to preserve data)\n    master = df_price.merge(df_metrics, on=merge_key, how='outer', suffixes=('', '_drop'))\n    master = master.merge(df_balance, on=merge_key, how='outer', suffixes=('', '_drop'))\n    master = master.merge(df_pl, on=merge_key, how='outer', suffixes=('', '_drop'))\n\n    # 3. Clean Duplicate Columns\n    cols_to_drop = [c for c in master.columns if '_drop' in c]\n    master.drop(columns=cols_to_drop, inplace=True)\n    \n    # 4. EXPORT STEP 1: The Master File\n    export_step(master, 'step1_master_financial_data.csv')\n    \n    return master\n\n\nmaster_df = merge_and_export_master(price_df, metrics_df, balance_df, pl_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T08:18:14.282146Z","iopub.execute_input":"2025-12-29T08:18:14.282401Z","iopub.status.idle":"2025-12-29T08:18:14.836522Z","shell.execute_reply.started":"2025-12-29T08:18:14.282373Z","shell.execute_reply":"2025-12-29T08:18:14.835891Z"}},"outputs":[{"name":"stdout","text":"üîÑ Starting Merge Process...\n‚úÖ Success: 'step1_master_financial_data.csv' has been generated with 4206 rows.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def transform_to_industry_formats(master_df):\n    \"\"\"\n    Iterates through the Master DF, identifies the industry, \n    applies the specific format mapping, and saves 5 separate CSVs.\n    \"\"\"\n    \n    # Containers for our 5 formats\n    saas_data = []\n    retail_data = []\n    mfg_data = []\n    consulting_data = []\n    hospitality_data = []\n    \n    # Iterate row by row\n    for _, row in master_df.iterrows():\n        industry = str(row.get('Industry', '')).lower()\n        \n        # --- COMMON CALCULATIONS ---\n        sales = row.get('Sales', 0)\n        op_profit = row.get('Operating profit', 0)\n        net_profit = row.get('Net profit', 0)\n        \n        # Safe retrieval of costs (handling NaNs)\n        material_cost = row.get('Material cost last year', 0) or 0\n        employee_cost = row.get('Employee cost last year', 0) or 0\n        depreciation = row.get('Depreciation', 0) or 0\n        \n        # --- MAPPING LOGIC ---\n        \n        # 1. SaaS / Tech Format\n        if any(x in industry for x in ['software', 'it', 'tech', 'computers']):\n            # Logic: Tech has low material cost. 'COGS' is usually server costs + support staff.\n            # We assume 20% of Employee Cost is \"Support\" (COGS), rest is R&D/Admin.\n            support_cost = employee_cost * 0.20\n            gross_margin = sales - support_cost\n            \n            saas_data.append({\n                'Company': row.get('Name'),\n                'Recurring_Revenue': sales,\n                'Cost_of_Revenue_Support': support_cost,\n                'Gross_Profit': gross_margin,\n                'OpEx_R_and_D_Staff': employee_cost * 0.80, # The rest of salaries\n                'EBITDA': op_profit,\n                'Net_Income': net_profit,\n                'Metric_Price_to_Sales': row.get('Price to Sales')\n            })\n\n        # 2. Retail Format\n        elif any(x in industry for x in ['retail', 'trading', 'department', 'fashion']):\n            # Logic: Material Cost is the main COGS. Inventory is critical.\n            retail_data.append({\n                'Company': row.get('Name'),\n                'Gross_Sales': sales,\n                'COGS_Merchandise': material_cost,\n                'Gross_Margin': sales - material_cost,\n                'Store_Operating_Expenses': (sales - material_cost) - op_profit, # Inferred back-calc\n                'Inventory_End_of_Period': row.get('Inventory'),\n                'Working_Capital': row.get('Working capital'),\n                'Net_Profit': net_profit\n            })\n\n        # 3. Manufacturing Format\n        elif any(x in industry for x in ['steel', 'auto', 'chemical', 'pharma', 'textile']):\n            # Logic: Heavy reliance on \"Gross Block\" (Machinery) and Depreciation.\n            mfg_data.append({\n                'Company': row.get('Name'),\n                'Factory_Revenue': sales,\n                'Direct_Materials': material_cost,\n                'Factory_Overhead_Depreciation': depreciation,\n                'Gross_Manufacturing_Profit': sales - material_cost - depreciation,\n                'Plant_Machinery_Asset_Value': row.get('Gross block'),\n                'Debt_Level': row.get('Debt'),\n                'Net_Income': net_profit\n            })\n\n        # 4. Hospitality Format (Restaurants/Hotels)\n        elif any(x in industry for x in ['hotel', 'restaurant', 'resort', 'hospitality']):\n            # Logic: \"Prime Cost\" = Food Cost (Material) + Labor (Employee).\n            prime_cost = material_cost + employee_cost\n            hospitality_data.append({\n                'Company': row.get('Name'),\n                'Total_Revenue': sales,\n                'COGS_Food_Beverage': material_cost,\n                'Labor_Cost': employee_cost,\n                'Prime_Cost': prime_cost, # The golden metric for this industry\n                'Prime_Cost_Percentage': (prime_cost / sales) if sales > 0 else 0,\n                'Rent_Occupancy_Cost': (sales - prime_cost - op_profit), # Inferred\n                'EBITDA': op_profit\n            })\n\n        # 5. Consulting / Services (Default for others)\n        else:\n            # Logic: People business. No material cost. Revenue is fees.\n            consulting_data.append({\n                'Company': row.get('Name'),\n                'Professional_Fees_Billed': sales,\n                'Direct_Consultant_Salaries': employee_cost,\n                'Contribution_Margin': sales - employee_cost,\n                'Corporate_Overheads': (sales - employee_cost) - op_profit,\n                'Net_Income': net_profit,\n                'ROI_Metric': row.get('Return on capital employed')\n            })\n\n    # --- EXPORT STEP 2: The 5 Formats ---\n    \n    # Convert lists to DataFrames and Export\n    outputs = [\n        (pd.DataFrame(saas_data), 'step2_format_saas.csv'),\n        (pd.DataFrame(retail_data), 'step2_format_retail.csv'),\n        (pd.DataFrame(mfg_data), 'step2_format_manufacturing.csv'),\n        (pd.DataFrame(consulting_data), 'step2_format_consulting.csv'),\n        (pd.DataFrame(hospitality_data), 'step2_format_hospitality.csv')\n    ]\n    \n    print(\"\\nüîÑ Generating Industry Formats...\")\n    for df, name in outputs:\n        if not df.empty:\n            export_step(df, name)\n        else:\n            print(f\"‚ö†Ô∏è Warning: No data found for {name} (Check industry tags)\")\n\n\ntransform_to_industry_formats(master_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T08:18:14.837360Z","iopub.execute_input":"2025-12-29T08:18:14.837674Z","iopub.status.idle":"2025-12-29T08:18:15.143229Z","shell.execute_reply.started":"2025-12-29T08:18:14.837645Z","shell.execute_reply":"2025-12-29T08:18:15.142487Z"}},"outputs":[{"name":"stdout","text":"\nüîÑ Generating Industry Formats...\n‚úÖ Success: 'step2_format_saas.csv' has been generated with 349 rows.\n‚úÖ Success: 'step2_format_retail.csv' has been generated with 478 rows.\n‚úÖ Success: 'step2_format_manufacturing.csv' has been generated with 828 rows.\n‚úÖ Success: 'step2_format_consulting.csv' has been generated with 2481 rows.\n‚úÖ Success: 'step2_format_hospitality.csv' has been generated with 70 rows.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import pandas as pd\nimport datetime\nimport os\nimport re\n\n# ==========================================\n# 1. The Rendering Engine (Class)\n# ==========================================\nclass IncomeStatementGenerator:\n    def __init__(self):\n        # Configuration: Maps Visual Labels to DataFrame Columns\n        self.templates = {\n            'SaaS': {\n                'title': 'SaaS Income Statement',\n                'schema': [\n                    ('Recurring Revenue', 'Recurring_Revenue', False),\n                    ('Cost of Revenue (Support)', 'Cost_of_Revenue_Support', True),\n                    ('---', '---', False),\n                    ('Gross Profit', 'Gross_Profit', False),\n                    ('Operating Expenses (R&D)', 'OpEx_R_and_D_Staff', True),\n                    ('---', '---', False),\n                    ('EBITDA', 'EBITDA', False),\n                    ('Net Income', 'Net_Income', False)\n                ]\n            },\n            'Retail': {\n                'title': 'Retail Operations P&L',\n                'schema': [\n                    ('Gross Sales', 'Gross_Sales', False),\n                    ('COGS (Merchandise)', 'COGS_Merchandise', True),\n                    ('---', '---', False),\n                    ('Gross Margin', 'Gross_Margin', False),\n                    ('Store OpEx', 'Store_Operating_Expenses', True),\n                    ('---', '---', False),\n                    ('Net Profit', 'Net_Profit', False),\n                    ('===', '===', False),\n                    ('Memo: Inventory', 'Inventory_End_of_Period', False)\n                ]\n            },\n            'Manufacturing': {\n                'title': 'Manufacturing Cost Sheet',\n                'schema': [\n                    ('Factory Revenue', 'Factory_Revenue', False),\n                    ('Direct Materials', 'Direct_Materials', True),\n                    ('Depreciation', 'Factory_Overhead_Depreciation', True),\n                    ('---', '---', False),\n                    ('Gross Mfg Profit', 'Gross_Manufacturing_Profit', False),\n                    ('---', '---', False),\n                    ('Net Income', 'Net_Income', False),\n                    ('===', '===', False),\n                    ('Memo: Plant Assets', 'Plant_Machinery_Asset_Value', False)\n                ]\n            },\n            'Hospitality': {\n                'title': 'Restaurant Statement of Operations',\n                'schema': [\n                    ('Total Revenue', 'Total_Revenue', False),\n                    ('COGS (Food & Bev)', 'COGS_Food_Beverage', True),\n                    ('Labor Cost', 'Labor_Cost', True),\n                    ('---', '---', False),\n                    ('PRIME COST', 'Prime_Cost', False),\n                    ('Occupancy/Rent', 'Rent_Occupancy_Cost', True),\n                    ('---', '---', False),\n                    ('EBITDA', 'EBITDA', False)\n                ]\n            },\n            'Consulting': {\n                'title': 'Professional Services P&L',\n                'schema': [\n                    ('Professional Fees', 'Professional_Fees_Billed', False),\n                    ('Direct Consultant Salaries', 'Direct_Consultant_Salaries', True),\n                    ('---', '---', False),\n                    ('Contribution Margin', 'Contribution_Margin', False),\n                    ('Corp Overheads', 'Corporate_Overheads', True),\n                    ('---', '---', False),\n                    ('Net Income', 'Net_Income', False)\n                ]\n            }\n        }\n\n    def _format_currency(self, amount):\n        if pd.isna(amount): return \"$0.00\"\n        try:\n            val = float(amount)\n            # Use parentheses for negative accounting format\n            if val < 0:\n                return f\"(${abs(val):,.2f})\"\n            return f\"${val:,.2f}\"\n        except:\n            return str(amount)\n\n    def generate(self, company_name, format_type, data_row):\n        template = self.templates.get(format_type)\n        if not template:\n            return f\"Error: Template for '{format_type}' not found.\"\n\n        # Header\n        lines = []\n        lines.append(\"=\"*60)\n        lines.append(f\"{str(company_name).upper()}\")\n        lines.append(f\"{template['title']}\")\n        lines.append(f\"Report Date: {datetime.date.today()}\")\n        lines.append(\"=\"*60)\n        lines.append(f\"{'Line Item':<40} | {'Amount':>15}\")\n        lines.append(\"-\" * 60)\n\n        # Body\n        for label, col_key, is_expense in template['schema']:\n            if label == '---':\n                lines.append(\"-\" * 60)\n                continue\n            if label == '===':\n                lines.append(\"=\" * 60)\n                continue\n\n            raw_val = data_row.get(col_key, 0)\n            \n            # Logic: If it's an expense line item, visually treat it as a deduction\n            # Note: The raw data might already be positive. We display expenses in ()\n            final_val = raw_val\n            if is_expense and raw_val > 0:\n                final_val = -raw_val\n            \n            val_str = self._format_currency(final_val)\n            lines.append(f\"{label:<40} | {val_str:>15}\")\n\n        lines.append(\"=\"*60 + \"\\n\")\n        return \"\\n\".join(lines)\n\n\n# ==========================================\n# 2. The Batch Processor\n# ==========================================\ndef run_batch_generation(dfs_dictionary, output_folder='Financial_Reports'):\n    \"\"\"\n    Iterates through specific_dfs, generates P&Ls, and saves text files.\n    \"\"\"\n    gen = IncomeStatementGenerator()\n    \n    # Create output directory\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n        print(f\"üìÅ Created directory: {output_folder}\")\n    \n    report_count = 0\n    \n    print(f\"üöÄ Starting Batch Processing for {len(dfs_dictionary)} Industries...\")\n    \n    for format_name, df in dfs_dictionary.items():\n        if df.empty:\n            print(f\"‚ö†Ô∏è  Skipping {format_name} (DataFrame is empty)\")\n            continue\n            \n        print(f\"   ... Processing {format_name} ({len(df)} companies)\")\n        \n        # Iterate through every company in this industry dataframe\n        for idx, row in df.iterrows():\n            company = row.get('Company', f'Unknown_Co_{idx}')\n            \n            # Generate the text content\n            statement_text = gen.generate(\n                company_name=company,\n                format_type=format_name,\n                data_row=row\n            )\n            \n            # Sanitize filename (remove special chars from company name)\n            safe_name = re.sub(r'[^\\w\\s-]', '', str(company)).strip().replace(' ', '_')\n            filename = f\"{output_folder}/{format_name}_{safe_name}.txt\"\n            \n            # Save to file\n            with open(filename, 'w', encoding='utf-8') as f:\n                f.write(statement_text)\n            \n            report_count += 1\n\n    print(f\"\\n‚úÖ Batch Complete! Generated {report_count} reports in '/{output_folder}'\")\n\n\n# ==========================================\n# 3. RUN IT (Using your specific_dfs)\n# ==========================================\n\n# Assuming 'specific_dfs' is already loaded in your environment from the previous steps.\n# If not, uncomment the lines below to load them from the CSVs we made earlier:\n\nspecific_dfs = {\n    'SaaS': pd.read_csv('step2_format_saas.csv'),\n    'Retail': pd.read_csv('step2_format_retail.csv'),\n    'Manufacturing': pd.read_csv('step2_format_manufacturing.csv'),\n    'Hospitality': pd.read_csv('step2_format_hospitality.csv'),\n    'Consulting': pd.read_csv('step2_format_consulting.csv')\n}\n\n# Execute\nif 'specific_dfs' in locals():\n    run_batch_generation(specific_dfs)\nelse:\n    print(\"‚ùå Error: 'specific_dfs' variable not found. Please ensure CSVs are loaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T08:18:15.144329Z","iopub.execute_input":"2025-12-29T08:18:15.144591Z","iopub.status.idle":"2025-12-29T08:18:15.997924Z","shell.execute_reply.started":"2025-12-29T08:18:15.144565Z","shell.execute_reply":"2025-12-29T08:18:15.997121Z"}},"outputs":[{"name":"stdout","text":"üöÄ Starting Batch Processing for 5 Industries...\n   ... Processing SaaS (349 companies)\n   ... Processing Retail (478 companies)\n   ... Processing Manufacturing (828 companies)\n   ... Processing Hospitality (70 companies)\n   ... Processing Consulting (2481 companies)\n\n‚úÖ Batch Complete! Generated 4206 reports in '/Financial_Reports'\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import torch\nfrom unsloth import FastLanguageModel\n\nmajor_version, minor_version = torch.cuda.get_device_capability()\nprint(f\"‚úÖ GPU Detected: CUDA Capability {major_version}.{minor_version}\")\nprint(\"‚úÖ Unsloth installed successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T08:18:15.999063Z","iopub.execute_input":"2025-12-29T08:18:15.999382Z","iopub.status.idle":"2025-12-29T08:18:16.004254Z","shell.execute_reply.started":"2025-12-29T08:18:15.999344Z","shell.execute_reply":"2025-12-29T08:18:16.003612Z"}},"outputs":[{"name":"stdout","text":"‚úÖ GPU Detected: CUDA Capability 7.5\n‚úÖ Unsloth installed successfully.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import pandas as pd\nimport json\nimport os\n\ndef convert_to_unsloth_jsonl(file_map, output_filename=\"financial_finetune.jsonl\"):\n    \"\"\"\n    Reads multiple CSVs and converts them into a single JSONL file \n    formatted for Unsloth / Alpaca fine-tuning.\n    \n    Args:\n        file_map (dict): Keys are 'Industry Name', Values are 'path_to_csv'.\n        output_filename (str): The name of the output JSONL file.\n    \"\"\"\n    \n    combined_data = []\n    \n    print(f\"üîÑ Starting conversion to {output_filename}...\")\n    \n    for industry, filepath in file_map.items():\n        if not os.path.exists(filepath):\n            print(f\"‚ö†Ô∏è  Skipping {industry}: File not found ({filepath})\")\n            continue\n            \n        df = pd.read_csv(filepath)\n        print(f\"   ... Processing {industry} ({len(df)} rows)\")\n        \n        for _, row in df.iterrows():\n            # 1. Clean the data (Handle NaNs)\n            # We convert row to dict and replace NaN with None or 0\n            row_dict = row.where(pd.notnull(row), None).to_dict()\n            \n            # 2. Construct the Prompt components\n            company_name = row_dict.get('Company', 'a company')\n            \n            # INSTRUCTION: The prompt you will give the AI\n            # We vary it slightly to make the model robust\n            instruction = f\"Generate a {industry} Income Statement for {company_name}.\"\n            \n            # INPUT: Optional context (usually empty for pure generation tasks)\n            # But we can add context if we want to simulate 'formatting' raw data\n            input_context = \"\" \n            \n            # OUTPUT: The exact JSON you want the AI to learn to generate\n            # We dump the row_dict as a JSON string\n            output_json = json.dumps(row_dict)\n            \n            # 3. Create the Training Entry\n            entry = {\n                \"instruction\": instruction,\n                \"input\": input_context,\n                \"output\": output_json\n            }\n            \n            combined_data.append(entry)\n\n    # 4. Save to JSONL\n    with open(output_filename, 'w') as f:\n        for entry in combined_data:\n            f.write(json.dumps(entry) + '\\n')\n            \n    print(f\"‚úÖ Success! Created {output_filename} with {len(combined_data)} training examples.\")\n    print(\"   You can now load this into Unsloth using load_dataset('json', data_files='...')\")\n\n# ==========================================\n# EXECUTION\n# ==========================================\n\n# Map your CSVs from the previous step\ncsv_files = {\n    'SaaS': 'step2_format_saas.csv',\n    'Retail': 'step2_format_retail.csv',\n    'Manufacturing': 'step2_format_manufacturing.csv',\n    'Hospitality': 'step2_format_hospitality.csv',\n    'Consulting': 'step2_format_consulting.csv'\n}\n\n# Run the converter\nconvert_to_unsloth_jsonl(csv_files)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T08:18:16.005399Z","iopub.execute_input":"2025-12-29T08:18:16.005681Z","iopub.status.idle":"2025-12-29T08:18:17.389576Z","shell.execute_reply.started":"2025-12-29T08:18:16.005647Z","shell.execute_reply":"2025-12-29T08:18:17.388745Z"}},"outputs":[{"name":"stdout","text":"üîÑ Starting conversion to financial_finetune.jsonl...\n   ... Processing SaaS (349 rows)\n   ... Processing Retail (478 rows)\n   ... Processing Manufacturing (828 rows)\n   ... Processing Hospitality (70 rows)\n   ... Processing Consulting (2481 rows)\n‚úÖ Success! Created financial_finetune.jsonl with 4206 training examples.\n   You can now load this into Unsloth using load_dataset('json', data_files='...')\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom datasets import load_dataset\n\n# 1. Configuration\nmax_seq_length = 2048\ndtype = None # Auto detection\nload_in_4bit = True # Use 4bit quantization to reduce memory usage\n\n# 2. Load Base Model (Llama-3 8B is excellent for JSON structure)\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n)\n\n# 3. Add LoRA Adapters (The \"Fine-Tuning\" Magic)\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Rank\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0,\n    bias = \"none\",\n    use_gradient_checkpointing = \"unsloth\",\n    random_state = 3407,\n    use_rslora = False,\n    loftq_config = None,\n)\n\n# 4. Prompt Formatting\nalpaca_prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Response:\n{}\"\"\"\n\nEOS_TOKEN = tokenizer.eos_token\ndef formatting_prompts_func(examples):\n    instructions = examples[\"instruction\"]\n    outputs      = examples[\"output\"]\n    texts = []\n    for instruction, output in zip(instructions, outputs):\n        text = alpaca_prompt.format(instruction, output) + EOS_TOKEN\n        texts.append(text)\n    return { \"text\" : texts, }\n\n# 5. Load Your Dataset\n# Replace 'your_dataset.jsonl' with the file from Step 1\ndataset = load_dataset(\"json\", data_files=\"financial_finetune.jsonl\", split=\"train\")\ndataset = dataset.map(formatting_prompts_func, batched = True)\n\n# 6. Train the Model\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    dataset_num_proc = 2,\n    packing = False,\n    args = TrainingArguments(\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 5,\n        max_steps = 60,\n        learning_rate = 2e-4,\n        \n        # --- HARDWARE FIXES FOR P100 ---\n        fp16 = True,           # P100 requires fp16\n        bf16 = False,          # P100 cannot do bf16\n        optim = \"adamw_8bit\",\n        \n        # --- PREVENT HANGING ---\n        report_to = \"none\",    # Disables WandB hanging\n        logging_steps = 1,     # Print progress every step\n        \n        output_dir = \"outputs\",\n        seed = 3407,\n    ),\n)\n\ntrainer.train()\nprint(\"‚úÖ Training Complete! Model is now a Financial Expert.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T08:18:17.390609Z","iopub.execute_input":"2025-12-29T08:18:17.390896Z","iopub.status.idle":"2025-12-29T08:23:26.968100Z","shell.execute_reply.started":"2025-12-29T08:18:17.390868Z","shell.execute_reply":"2025-12-29T08:23:26.967302Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.12.9: Fast Llama patching. Transformers: 4.57.1.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2780aefe13af4e238c35a3bbc163ff03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4206 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d88d54ccf65b4ee7a22e9224f367300d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/4206 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"185bce6d72dc499c932c104f02781e20"}},"metadata":{}},{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 2\n   \\\\   /|    Num examples = 4,206 | Num Epochs = 1 | Total steps = 60\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 04:39, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.687200</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.680200</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.659500</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.768000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.614800</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.687800</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2.617400</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2.450900</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.403200</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.212600</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>2.231800</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>2.149600</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.170400</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>1.971700</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>1.893100</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>1.881800</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.848000</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.714600</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.549500</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.593300</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.392100</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.441200</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>1.452000</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.416100</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.313300</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.229200</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.311800</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.261100</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.150600</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.060000</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>1.019600</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>1.049000</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.941600</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>1.001700</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>1.045100</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.867600</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>0.888200</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.951400</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>0.818400</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.833400</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>0.773100</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.861400</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>0.800700</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.808500</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.845800</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.868400</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>0.835500</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.720400</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>0.773500</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.719200</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>0.776300</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>0.756600</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>0.753900</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>0.745700</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.768700</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0.709800</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>0.829500</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>0.726800</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>0.828000</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.693900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"‚úÖ Training Complete! Model is now a Financial Expert.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import torch\nfrom unsloth import FastLanguageModel\nimport json\nimport plotly.graph_objects as go\nimport re\n\n# ==========================================\n# 1. SETUP & CONFIGURATION\n# ==========================================\n# Enable native 2x faster inference\nFastLanguageModel.for_inference(model)\n\n# Define the Prompt Template (Must match training data EXACTLY)\n# Note: We removed the '### Input:' section to prevent model confusion\nalpaca_prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Response:\n\"\"\"\n\n# The specific request\ninstruction = \"Generate a SaaS Income Statement for a high-growth AI startup.\"\n\n# ==========================================\n# 2. RUN INFERENCE (GENERATION)\n# ==========================================\nprint(\"ü§ñ Generating Synthetic Financials...\")\ninputs = tokenizer(\n    [alpaca_prompt.format(instruction)], \n    return_tensors=\"pt\"\n).to(\"cuda\")\n\noutputs = model.generate(\n    **inputs, \n    max_new_tokens=512, \n    use_cache=True,\n    temperature=0.8, # Higher temp = more creative numbers\n)\n\n# Decode the output\ngenerated_text = tokenizer.batch_decode(outputs)[0]\n\n# ==========================================\n# 3. PARSE JSON (ROBUSTLY)\n# ==========================================\nfinancial_data = None\ntry:\n    # 1. Isolate the JSON part (everything after \"### Response:\")\n    response_part = generated_text.split(\"### Response:\")[-1].strip()\n    response_part = response_part.replace(\"<|end_of_text|>\", \"\")\n    \n    # 2. Attempt to parse\n    financial_data = json.loads(response_part)\n    print(\"\\n‚úÖ Successfully Parsed JSON:\")\n    print(json.dumps(financial_data, indent=2))\n\nexcept json.JSONDecodeError:\n    # Fallback: Try to find the first '{' and last '}' using Regex\n    try:\n        match = re.search(r\"\\{.*\\}\", response_part, re.DOTALL)\n        if match:\n            financial_data = json.loads(match.group(0))\n            print(\"\\n‚úÖ Recovered JSON via Regex:\")\n            print(json.dumps(financial_data, indent=2))\n        else:\n            print(\"\\n‚ùå Parsing Failed. Raw Output below:\")\n            print(response_part)\n    except:\n        print(\"\\n‚ùå Critical Parsing Error. Raw Output below:\")\n        print(response_part)\n\n# ==========================================\n# 4. VISUALIZE (WATERFALL CHART)\n# ==========================================\ndef plot_robust_waterfall(data):\n    if not data: return\n\n    # --- Helper to handle AI Aliases ---\n    def get_val(keys):\n        for k in keys:\n            if k in data: return data[k]\n        return 0\n\n    # 1. Extract Values (Looking for variations in keys)\n    revenue = get_val(['Recurring_Revenue', 'Revenue', 'Total_Revenue', 'Sales', 'Gross_Sales'])\n    cor     = get_val(['Cost_of_Revenue', 'Cost_of_Revenue_Support', 'COGS', 'Direct_Costs'])\n    gp      = get_val(['Gross_Profit', 'Gross_Margin'])\n    \n    # If Gross Profit is 0/Missing, calculate it\n    if gp == 0 and revenue > 0:\n        gp = revenue - cor\n\n    # Operating Expenses\n    rnd     = get_val(['R_and_D', 'OpEx_R_and_D_Staff', 'Research_and_Development'])\n    sales   = get_val(['Sales_Marketing', 'S_and_M', 'Marketing'])\n    ga      = get_val(['G_and_A', 'General_Administrative', 'Admin'])\n    \n    # If granular OpEx is missing, look for a \"Total OpEx\" key\n    total_opex = rnd + sales + ga\n    if total_opex == 0:\n        total_opex = get_val(['Operating_Expenses', 'OpEx', 'Total_Expenses'])\n\n    # EBITDA\n    ebitda = get_val(['EBITDA', 'Operating_Income', 'Operating_Profit'])\n    if ebitda == 0:\n        ebitda = gp - total_opex\n\n    # 2. Build Plot Data\n    fig = go.Figure(go.Waterfall(\n        name = \"2025\", orientation = \"v\",\n        measure = [\"absolute\", \"relative\", \"total\", \"relative\", \"relative\", \"relative\", \"total\"],\n        x = [\"Revenue\", \"Cost of Revenue\", \"Gross Profit\", \"R&D\", \"Sales & Mkt\", \"G&A\", \"EBITDA\"],\n        textposition = \"outside\",\n        text = [f\"${x/1e6:.1f}M\" if x!=0 else \"\" for x in [revenue, -cor, gp, -rnd, -sales, -ga, ebitda]],\n        y = [revenue, -cor, 0, -rnd, -sales, -ga, 0],\n        connector = {\"line\":{\"color\":\"rgb(63, 63, 63)\"}},\n        decreasing = {\"marker\":{\"color\":\"#EF553B\"}},\n        increasing = {\"marker\":{\"color\":\"#00CC96\"}},\n        totals     = {\"marker\":{\"color\":\"#19D3F3\"}}\n    ))\n\n    fig.update_layout(\n        title = f\"Synthetic P&L: {data.get('Company', 'AI Startup')}\",\n        template = \"plotly_dark\",\n        showlegend = False,\n        height=650\n    )\n    \n    fig.show()\n\n# Run Plot\nif financial_data:\n    plot_robust_waterfall(financial_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T08:30:59.414230Z","iopub.execute_input":"2025-12-29T08:30:59.414564Z","iopub.status.idle":"2025-12-29T08:31:08.744062Z","shell.execute_reply.started":"2025-12-29T08:30:59.414534Z","shell.execute_reply":"2025-12-29T08:31:08.743457Z"}},"outputs":[{"name":"stdout","text":"ü§ñ Generating Synthetic Financials...\n\n‚úÖ Successfully Parsed JSON:\n{\n  \"Company\": \"Mantle AI\",\n  \"Recurring_Revenue\": 6.7,\n  \"Contribution_Margin\": 3.7,\n  \"Corporate_Overheads\": 3.3,\n  \"Net_Income\": 0.6,\n  \"Weighted_Average_Shares_Outstanding\": 8.1,\n  \"Revenue_Growth\": 1.3,\n  \"Contribution_Margin_Growth\": 1.3,\n  \"Net_Income_Growth\": 1.3,\n  \"Free_Cash_Flow\": 1.2,\n  \"Adjusted_Free_Cash_Flow\": 1.2,\n  \"Gross_Margin\": 5.4\n}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"3886819d-0a4f-412e-bd25-4a8ef5e5c9a9\" class=\"plotly-graph-div\" style=\"height:650px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3886819d-0a4f-412e-bd25-4a8ef5e5c9a9\")) {                    Plotly.newPlot(                        \"3886819d-0a4f-412e-bd25-4a8ef5e5c9a9\",                        [{\"connector\":{\"line\":{\"color\":\"rgb(63, 63, 63)\"}},\"decreasing\":{\"marker\":{\"color\":\"#EF553B\"}},\"increasing\":{\"marker\":{\"color\":\"#00CC96\"}},\"measure\":[\"absolute\",\"relative\",\"total\",\"relative\",\"relative\",\"relative\",\"total\"],\"name\":\"2025\",\"orientation\":\"v\",\"text\":[\"$0.0M\",\"\",\"$0.0M\",\"\",\"\",\"\",\"$0.0M\"],\"textposition\":\"outside\",\"totals\":{\"marker\":{\"color\":\"#19D3F3\"}},\"x\":[\"Revenue\",\"Cost of Revenue\",\"Gross Profit\",\"R&D\",\"Sales & Mkt\",\"G&A\",\"EBITDA\"],\"y\":[6.7,0,0,0,0,0,0],\"type\":\"waterfall\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"lakecolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#506784\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"dark\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"bgcolor\":\"rgb(17,17,17)\",\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"bordercolor\":\"rgb(17,17,17)\",\"borderwidth\":1,\"tickwidth\":0},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"bgcolor\":\"rgb(17,17,17)\",\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Synthetic P&L: Mantle AI\"},\"showlegend\":false,\"height\":650},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('3886819d-0a4f-412e-bd25-4a8ef5e5c9a9');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}